---
title: "Task 1 - ST443 Project"
author: "Yavuz Kaan Celep"
date: "`r Sys.Date()`"
output: html_document
---

## Libraries and Data Importing:

```{r setup, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(443)
library(ggplot2)
library(DataExplorer)
library(GGally)
library(tidyverse)
library(MASS)
library(class)
library(pROC)
library(caret) 
library(adabag)
library(mboost)   
library(gbm)
library(xgboost) 
library(randomForest)
library(ranger)
library(e1071)
library(lattice)
library(corrplot)
```

```{r reading in data, echo=TRUE}
task1data <- read.csv("C:/Users/DELL/Desktop/data1.csv")
task1data$label <- if_else(task1data$label == "TREG", 1, 0)
```

Here we adjust the *label* column to a factor column, with *TREG* being 1 and *CD4+T* 0. 
```{r label-to-factor}
table(task1data$label, useNA = "ifany")
```

#plot - for the outliers.
#What are the features with the highest sparsity?
#Each columns' average, gene expression levels.


## T1.1 

```{r missing data, echo=TRUE}

abc <- task1data |> is.na() |> colSums() |> table()
if (abc[1] == ncol(task1data)){
  print("We have that there are no missing data in any columns which will be helpful in our analysis")
}
```

```{r sparsity, echo=FALSE}
total_zeros <- sum(rowSums(task1data == 0))
total_entries <- 5471 * 4124
total_zeros / total_entries
```
Our given data is reasonably sparse. In fact, below we have shown that approximately 66.2% of this dataset are zero entries. We can explore sparsity across the covariates as well. 

``` {r covariate sparsity, echo=TRUE}
covariate_sparsities <- data.frame(Gene = colnames(task1data)[-1], 
                                   Sparsity = rep(0, ncol(task1data)-1)) 

for (i in 2:ncol(task1data)){
  count <- length(which(task1data[,i] == 0))
  covariate_sparsities$Sparsity[i-1] <- count / nrow(task1data)
}

summary(covariate_sparsities)
ggplot(covariate_sparsities, aes(Sparsity)) + 
  geom_histogram(color = "black", fill = "white" ,bins = 40) + 
  ggtitle("Distribution of Sparsity Rates Across Covariates") + 
  theme_bw()

```

```{r}
plot_correlation(task1data[1:5]) 
```

```{r}
ggpairs(data = task1data[1:5])
```


## T1.2 

```{r functions, echo=TRUE}

eval_metrics <- function(method, table){
  # setup
  TN <- table[[1]]
  FN <- table[[2]]
  FP <- table[[3]]
  TP <- table[[4]]
  
  # metrics
  accuracy <- 1 - ((FN + FP) / sum(table))
  BA <- .5 * (TP / (TP + FN)) + .5 * (TN / (TN + FP))
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- (precision * recall) / (precision + recall)
  
  # output
  return(data.frame("Method" = method,
                    "Accuracy" = accuracy,
                    "Balanced Accuracy" = BA,
                    "F1" = F1))
}

methods <- c(c("Random Forest", rf_conf_matrix), 
             c("KNN", knn_conf_matrix), 
             c("Logistic Regression", logistic_conf_matrix), 
             c("LDA", lda_conf_matrix))

```

#### Linear Discriminant Analysis
```{r lda setup, echo=TRUE}
train <- sample(c(TRUE, FALSE), nrow(task1data), replace=TRUE, prob=c(0.75,0.25))
test <- !train
task1_train <- task1data[train,]
task1_test <- task1data[test,]
```


```{r lda fit}
lda_fit <- lda(label ~ ., data = task1data, subset = train)
```

```{r lda predict}
lda_pred_full <-  predict(lda_fit, task1_test)
lda_pred <- predict(lda_fit, task1_test)$class

test_labels <- task1data$label[test]
lda_conf_matrix <- table(lda_pred, test_labels)
```



```{r lda eval, echo=TRUE}
lda_conf_matrix

eval_metrics(lda_conf_matrix)
lda_roc <- roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0, 1), direction = "<")
auc(lda_roc)

```


#### Logistic Regression
```{r logistic regression, echo=TRUE}

logistic_fit <- glm(label ~ ., data = task1data, subset = train, family = binomial)
logistic_probs <-  predict(logistic_fit, type = "response")
```

```{r logit eval}
logistic_pred <-  rep(0, nrow(task1_train))
logistic_pred[logistic_probs > .5] <-  1

tail(cbind(task1_train$label,logistic_pred))
logistic_conf_matrix <- table(logistic_pred, task1_train$label)
eval_metrics(logistic_conf_matrix)
```

#### Quadratic Discriminant Analysis
```{r qda, echo=TRUE}

qda_fit <- qda(label ~ ., data = task1data, subset = train)

qda_pred <- predict(qda_fit, Smarket_test)$class

table(qda_pred, task1_test)

mean(qda_pred != task1_test)

```

#### k-NN:
```{r knn, echo=TRUE}

knn <- knn(task1_train, task1_test, task1data$label[train], k=1)

knn_conf_matrix <- table(knn, task1data$label[test])

eval_metrics(knn_conf_matrix)
```

#### Gradient Boosting Decision Trees:

```{r GBDT}

gbdt <- gbm(label ~ ., data = task1_train, 
                   distribution = "gaussian", 
                   n.trees = 1000, 
                   interaction.depth = 4, 
                   shrinkage = .001, 
                   cv.folds = 5, 
                   verbose = FALSE)
gbdt_preds <- predict(gbdt, newdata = task1_test, n.trees = 1000)

```


#### Random Forest:

```{r echo=TRUE}

rf <- ranger(label~., 
             data = task1_train, 
             mtry = ncol(task1_train) |> sqrt() |> round(digits = 0),
             importance = "none",
             write.forest = TRUE,
             num.trees = 1000,
             classification = TRUE,
             verbose = TRUE)

rf_preds <- predict(rf, data=task1_test)$predictions

rf_conf_matrix <- table(rf_preds, task1data$label[test])


```

#### Support Vector Machines: 
```{r}
cost = 10 #This is the regularisation parameter.
svmfit = svm(label ~ ., data = task1_train, kernel = "linear", cost = cost, scale = FALSE)

svm_predictions <- predict(svm_model, test_data)
```

## T1.2.PCA 

```{r}
PCA <- prcomp(x = task1data)
Table_PCA <- rbind(PCA$rotation, summary(PCA)$importance)
print(Table_PCA[ ,1:10])

summary(PCA[ ,1:10])

par(mfrow=c(1,1))
plot(Table_PCA['Proportion of Variance',], type = 'l', lwd = 5, col = 'blue', xlim = c(1,4), main = 'PC proportions of total variance', xlab = 'PC', ylab = 'Proportion of variance', axes = FALSE)
axis(1, 1:10)
axis(2)
```


## T1.3

One classifier to improve upon is Gradient Boosted Decision Trees, namely by tuning the hyperparameters. 

```{r, echo=TRUE}
# Define grid of lambda (shrinkage) values to evaluate
lambda_grid <- c(0.001, 0.01,0.03,0.05)

# Initialize a vector to store test errors for each lambda
test_errors <- numeric(length(lambda_grid))
```

```{r}
# Loop over each lambda value
for (i in seq_along(lambda_grid)) {
  lambda <- lambda_grid[i]
  
  # Train the gbm model with the current lambda (shrinkage) value
  gbm_model <- gbm(label ~ ., data = task1_train, 
                   distribution = "gaussian", 
                   n.trees = 1000, 
                   interaction.depth = 4, 
                   shrinkage = lambda, 
                   cv.folds = 5, 
                   verbose = FALSE)
  
  # Make predictions on the test set using the optimal number of trees
  predictions <- predict(gbm_model, newdata = task1_test, n.trees = 1000)
  
  # Calculate the Mean Squared Error on the test set
  test_errors[i] <- mean((predictions - task1_test$label)^2)
}
```

```{r}
# Combine lambda values and test errors into a data frame for plotting
error_df <- data.frame(lambda = lambda_grid, test_error = test_errors)

# Plot the test error over the range of lambda values
ggplot(error_df, aes(x = lambda, y = test_error)) +
  geom_line() +
  geom_point() +
  labs(title = "Test Error vs Lambda (Shrinkage)", 
       x = "Lambda (Shrinkage)", 
       y = "Test Mean Squared Error") +
  theme_minimal()
```


```{r summary table}


# need to add ROC / AUC info
summary_table <- rbind(eval_metrics("LDA", lda_conf_matrix), 
                       eval_metrics("Logistic Regression", logistic_conf_matrix),
                       eval_metrics("KNN", knn_conf_matrix),
                       eval_metrics("Random Forest", rf_conf_matrix))


```





