---
title: "Task 1 - ST443 Project"
author: "Finbar Rhodes"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(443)
library(ggplot2)
library(tidyverse)
library(MASS)
library(class)
library(pROC)
library(caret) 
#library(adabag) # For the AdaBoost algorithm
library(mboost)   # For gamboost
library (gbm) # Gradient Boosting Machines
library(xgboost) #Extreme Gradient Boosting
library(randomForest)
library(ranger)
library(e1071)
library(lattice)
```

```{r reading in data, echo=TRUE}
task1data <- read.csv("/Users/finbarrhodes/Documents/ST443/Final Project/data1.csv.gz")
task1data$label <- if_else(task1data$label == "TREG", 1, 0)

```

Here we adjust the *label* column to a factor column, with *TREG* being 1 and *CD4+T* being 0
```{r label-to-factor}
table(task1data$label, useNA = "ifany")
```


## T1.1

```{r missing data, echo=TRUE}

abc <- task1data |> is.na() |> colSums() |> table()
if (abc[1] == ncol(task1data)){
  print("We have that there are no missing data in any columns which will be hekpful in our analysis")
}
```

```{r sparsity, echo=FALSE}
total_zeros <- sum(rowSums(task1data == 0))
total_entries <- 5471 * 4124
total_zeros / total_entries
```
Our given data is reasonably sparse. In fact, below we have shown that approximately 66.2% of this dataset are zero entries. We can explore sparsity across the covariates as well. 

``` {r covariate sparsity, echo=TRUE}
covariate_sparsities <- data.frame(Gene = colnames(task1data)[-1], 
                                   Sparsity = rep(0, ncol(task1data)-1)) 

for (i in 2:ncol(task1data)){
  count <- length(which(task1data[,i] == 0))
  covariate_sparsities$Sparsity[i-1] <- count / nrow(task1data)
}

summary(covariate_sparsities)
ggplot(covariate_sparsities, aes(Sparsity)) + 
  geom_histogram(color = "black", fill = "white" ,bins = 40) + 
  ggtitle("Distribution of Sparsity Rates Across Covariates") + 
  theme_bw()


barplot(colMeans(task1data[2:ncol(task1data)]))

```
can ask the question if all features are truly of use

```{r heatmap}

task1matrix <- sapply(task1data, as.numeric) |> as.matrix()

pal <- colorRampPalette(c("red", "yellow"), space = "rgb") 
levelplot(task1matrix, main="Task 1 Data Heatmap", xlab=" ", ylab=" ", col.regions=pal(40), cuts=3, at=seq(0,1,0.5))#, useRaster = TRUE)


```


## T1.2 

```{r functions, echo=TRUE}

eval_metrics <- function(str, table){
  # setup
  TN <- table[[1]]
  FN <- table[[2]]
  FP <- table[[3]]
  TP <- table[[4]]
  
  # metrics
  accuracy <- 1 - ((FN + FP) / sum(table))
  BA <- .5 * (TP / (TP + FN)) + .5 * (TN / (TN + FP))
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- (precision * recall) / (precision + recall)
  
  # output
  return(data.frame("Method" = str,
                    "Accuracy" = accuracy,
                    "Balanced Accuracy" = BA,
                    "F1" = F1))
}

methods <- c(c("Random Forest", rf_conf_matrix), 
             c("KNN", knn_conf_matrix), 
             c("Logistic Regression", logistic_conf_matrix), 
             c("LDA", lda_conf_matrix))

```

#### LDA
```{r lda setup, echo=TRUE}
train <- sample(c(TRUE, FALSE), nrow(task1data), replace=TRUE, prob=c(0.75,0.25))
test <- !train
task1_train <- task1data[train,]
task1_test <- task1data[test,]

```


```{r lda fit}
lda_fit <- lda(label ~ ., data = task1data, subset = train)
```

```{r lda predict}
lda_pred_full <-  predict(lda_fit, task1_test)
lda_pred <- predict(lda_fit, task1_test)$class

test_labels <- task1data$label[test]
lda_conf_matrix <- table(lda_pred, test_labels)
```



```{r lda eval, echo=TRUE}
lda_conf_matrix

eval_metrics(str = "LDA", table = lda_conf_matrix)

```


#### Logistic Regression
```{r logistic regression, echo=TRUE}

logistic_fit <- glm(label ~ ., data = task1data, family = binomial)
logistic_probs <-  predict(logistic_fit, type = "response")
```

```{r logit eval}
logistic_pred <-  rep(0, nrow(task1_train))
logistic_pred[logistic_probs > .5] <-  1

# tail(cbind(task1_train$label,logistic_pred))
logistic_conf_matrix <- table(logistic_pred, task1data$label)
eval_metrics("Logisitc Regression", logistic_conf_matrix)
```

#### QDA
```{r qda, echo=TRUE}

qda_fit <- qda(label ~ ., data = task1data, subset = train)

```

#### KNN
```{r knn, echo=TRUE}

knn <- knn(task1_train, task1_test, task1data$label[train], k=1)

knn_conf_matrix <- table(knn, task1data$label[test])

eval_metrics(knn_conf_matrix)
```

#### GBDT

```{r GBDT}

gbdt <- gbm(label ~ ., data = task1_train, 
                   distribution = "gaussian", 
                   n.trees = 1000, 
                   interaction.depth = 4, 
                   shrinkage = .001, 
                   cv.folds = 5, 
                   verbose = TRUE)

gbdt_preds <- predict(gbdt, newdata = task1_test, n.trees = 1000)

```


#### Random Forest

```{r echo=TRUE}

rf <- ranger(label~., 
             data = task1_train, 
             mtry = ncol(task1_train) |> sqrt() |> round(digits = 0),
             importance = "none",
             write.forest = TRUE,
             num.trees = 1000,
             classification = TRUE,
             verbose = TRUE)

rf_preds <- predict(rf, data=task1_test)$predictions

rf_conf_matrix <- table(rf_preds, task1data$label[test])


```






#### SVM
```{r}
cost = 10 #This is the regularisation parameter.
svmfit = svm(label ~ ., data = task1_train, kernel = "linear", cost = cost, scale = FALSE)

svm_predictions <- predict(svm_model, test_data)
```

## T1.2.PCA 

```{r}
PCA <- prcomp(x = task1data)
Table_PCA <- rbind(PCA$rotation, summary(PCA)$importance)
print(Table_PCA[ ,1:10])

summary(PCA[ ,1:10])

par(mfrow=c(1,1))
plot(Table_PCA['Proportion of Variance',], type = 'l', lwd = 5, col = 'blue', xlim = c(1,4), main = 'PC proportions of total variance', xlab = 'PC', ylab = 'Proportion of variance', axes = FALSE)
axis(1, 1:10)
axis(2)
```



## T1.3

Classifiers to tweak:
- KNN
- GBTM
- 

One classifier to improve upon is Gradient Boosted Decision Trees, namely by tuning the hyperparameters. 

```{r, echo=TRUE}
# Define grid of lambda (shrinkage) values to evaluate
lambda_grid <- c(0.001, 0.01,0.03,0.05)

# Initialize a vector to store test errors for each lambda
test_errors <- numeric(length(lambda_grid))
```

```{r}
# Loop over each lambda value
for (i in seq_along(lambda_grid)) {
  lambda <- lambda_grid[i]
  
  # Train the gbm model with the current lambda (shrinkage) value
  gbm_model <- gbm(label ~ ., data = task1_train, 
                   distribution = "gaussian", 
                   n.trees = 1000, 
                   interaction.depth = 4, 
                   shrinkage = lambda, 
                   cv.folds = 5, 
                   verbose = FALSE)
  
  # Make predictions on the test set using the optimal number of trees
  predictions <- predict(gbm_model, newdata = task1_test, n.trees = 1000)
  
  # Calculate the Mean Squared Error on the test set
  test_errors[i] <- mean((predictions - task1_test$label)^2)
}
```

```{r}
# Combine lambda values and test errors into a data frame for plotting
error_df <- data.frame(lambda = lambda_grid, test_error = test_errors)

# Plot the test error over the range of lambda values
ggplot(error_df, aes(x = lambda, y = test_error)) +
  geom_line() +
  geom_point() +
  labs(title = "Test Error vs Lambda (Shrinkage)", 
       x = "Lambda (Shrinkage)", 
       y = "Test Mean Squared Error") +
  theme_minimal()
```


```{r summary table}


# need to add ROC / AUC info
summary_table <- rbind(eval_metrics("LDA", lda_conf_matrix), 
                       eval_metrics("Logistic Regression", logistic_conf_matrix),
                       eval_metrics("KNN", knn_conf_matrix),
                       eval_metrics("Random Forest", rf_conf_matrix))

#summary_table$AUC <- c(auc(roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0,1), direction = "<")),
 #                      auc(roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0,1), direction = "<")),
  #                     auc(roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0,1), direction = "<")),
   #                    auc(roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0,1), direction = "<")))
  
lda_roc <- roc(task1_test$label, lda_pred_full$posterior[,2], levels = c(0, 1), direction = "<")
auc(lda_roc)


```





