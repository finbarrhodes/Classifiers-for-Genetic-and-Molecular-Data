---
title: "Untitled"
output: html_document
date: "2024-12-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
library(data.table)
library(dplyr)
library(ggplot2)
library(caret)

# STEP 1 DATA COLLECTION ---------

data <- read.csv("data2.csv.gz")
# Iterate through label and make them 0 if they are -1, 1 otherwise

# STEP 1.0. DATA PREPARATION ---------
for (i in 1:nrow(data)) {
  if (data[i, 1] == -1) {
    data[i, 1] <- 0  
  } else {
    data[i, 1] <- 1
  }
}
# Find duplicate columns
unique_data <- data[, !duplicated(as.list(data))]
num_repeated <- ncol(data) - ncol(unique_data)
cat("The new dataset has dimensions:", dim(unique_data), "\n")
# Calculate row indices for each split
set.seed(12)  # Set seed for reproducibility
unique_data <- unique_data[sample(nrow(unique_data)), ]
n <- nrow(unique_data)
end_training <- floor(n * 0.7)  # 70% for training
end_validation <- floor(n * 0.85)  # Next 10% for validation

# Split the data into training, validation, and testing sets
training_data <- unique_data[1:end_training, ]  # 70% of the data
validation_data <- unique_data[(end_training + 1):end_validation, ]  # 10% of the data
testing_data <- unique_data[(end_validation + 1):n, ]  # Remaining 20% of the data


# DATA SPLITING ---------
#create dep. var
y_train <- training_data[,1]
y_valid <- validation_data[,1]
y_test <- testing_data[,1]
#create training, validation and testing matrix with ind.var
features_train <- training_data[,-1]
sparse_data_train <- as(features_train, "sparseMatrix")
features_val <- validation_data[,-1]
sparse_data_valid <- as(features_val, "sparseMatrix")
features_test<- testing_data[,-1]
sparse_data_test <- as(features_test, "sparseMatrix")

```

```{r}
library(xgboost)
library(Matrix)
library(glmnet)
library(caTools)
library(SparseM)

# DATA CONVERTION ---------
# Convert to DMatrix format for XGBoost
dtrain_xg <- xgb.DMatrix(data = sparse_data_train, label = y_train)
dvalid_xg <- xgb.DMatrix(data = sparse_data_valid, label = y_valid)
dtest_xg <- xgb.DMatrix(data = sparse_data_test, label = y_test)



```

```{r}
library(xgboost)
library(data.table)


# Define the parameter grid
param_grid_xg <- expand.grid(
  max_depth = c(8),             # Tree depth
  eta = c(0.2),      # Learning rate
  subsample = c(0.8),            # Fraction of rows sampled per boosting round
  colsample_bytree = c(0.6 , 0.8),     # Fraction of features sampled per tree
  min_child_weight = c(1 , 2),      # Minimum sum of instance weight needed in a child
  gamma = c(0.1 , 0.3),             # Minimum loss reduction for further partitioning
  alpha = c(3 , 5)                 # L2 regularization term
)


# # Define the parameter grid
# param_grid_xg <- expand.grid(
#   max_depth = c(4, 6, 8),             # Tree depth
#   eta = c(0.01, 0.05, 0.1, 0.2),      # Learning rate
#   subsample = c(0.6, 0.8),            # Fraction of rows sampled per boosting round
#   colsample_bytree = c(0.6, 0.8),     # Fraction of features sampled per tree
#   min_child_weight = c(1, 3, 5),      # Minimum sum of instance weight needed in a child
#   gamma = c(0, 0.1, 0.5),             # Minimum loss reduction for further partitioning
#   alpha = c(1, 2, 3, 5)                 # L2 regularization term
# )

# Track the best model and results
best_model_xg <- NULL
best_logloss_xg <- Inf
best_params_xg <- NULL

# Create a data frame to store results
cv_results <- data.frame(
  max_depth = integer(),
  eta = numeric(),
  subsample = numeric(),
  colsample_bytree = numeric(),
  min_child_weight = numeric(),
  gamma = numeric(),
  lambda = numeric(),
  logloss = numeric(),
  stringsAsFactors = FALSE
)

# Cross-validation loop
set.seed(12)  # For reproducibility
for (i in 1:nrow(param_grid_xg)) {
  
  params_xg <- list(
    booster = "gbtree",
    objective = "binary:logistic",
    eval_metric = "logloss",
    max_depth = param_grid_xg$max_depth[i],
    eta = param_grid_xg$eta[i],
    subsample = param_grid_xg$subsample[i],
    colsample_bytree = param_grid_xg$colsample_bytree[i],
    min_child_weight = param_grid_xg$min_child_weight[i],
    gamma = param_grid_xg$gamma[i],
    alpha = param_grid_xg$alpha[i]
  )
  
  # Perform cross-validation
  cv <- xgb.cv(
    params = params_xg,
    data = dtrain_xg,
    nrounds = 100,
    nfold = 5
    ,                        # 5-fold cross-validation
    early_stopping_rounds = 10,       # Stop if no improvement for 10 rounds
    verbose = FALSE
  )
  
  # Get the best logloss for this combination of parameters
  min_logloss <- min(cv$evaluation_log$test_logloss_mean)
  
  # Store the results
  cv_results <- rbind(cv_results, data.frame(
    max_depth = param_grid_xg$max_depth[i],
    eta = param_grid_xg$eta[i],
    subsample = param_grid_xg$subsample[i],
    colsample_bytree = param_grid_xg$colsample_bytree[i],
    min_child_weight = param_grid_xg$min_child_weight[i],
    gamma = param_grid_xg$gamma[i],
    alpha = param_grid_xg$alpha[i],
    logloss = min_logloss
  ))
  
  
  # Update the best model if the logloss improves
  if (min_logloss < best_logloss_xg) {
    best_logloss_xg <- min_logloss
    best_model_xg <- params_xg
    best_params_xg_detailed <- params_xg
  }
  print(i)
}

# Initialize a data frame to store results
if (!exists("model_results_xg")) {
  model_results_xg <- data.frame(
    eta = numeric(),
    max_depth = integer(),
    subsample = numeric(),
    min_child_weight = numeric(),
    gamma = numeric(),
    alpha = numeric(),
    colsample_bytree = numeric(),
    logloss = numeric(),
    stringsAsFactors = FALSE
  )
}

# Append the best_model parameters and log loss
model_results_xg <- rbind(
  model_results_xg,
  data.frame(
    eta = best_model_xg$eta,
    max_depth = best_model_xg$max_depth,
    subsample = best_model_xg$subsample,
    colsample_bytree = best_model_xg$colsample_bytree,
    min_child_weight = best_model_xg$min_child_weight,
    gamma = best_model_xg$gamma,
    alpha = best_model_xg$alpha,
    logloss = best_logloss_xg  # Use the corresponding logloss for the best model
  )
)

# Print the updated table
print(model_results_xg)
print(best_model_xg)


# Print the best parameters and the corresponding logloss
print("Best Hyperparameters for XGBoost:")
print(best_params_xg_detailed)
print(paste("Best Logloss:", best_logloss_xg))

# View the complete cross-validation results
print(cv_results)




```




```{r}
set.seed(12)
initial_threshold <- sum(y_valid)/length(y_valid)
# Custom balanced accuracy function
balanced_accuracy <- function(preds, dtrain) {
  labels <- getinfo(dtrain, "label")
  preds_binary <- ifelse(preds > initial_threshold, 1, 0)
  
  tn <- sum(preds_binary == 0 & labels == 0)
  tp <- sum(preds_binary == 1 & labels == 1)
  fp <- sum(preds_binary == 1 & labels == 0)
  fn <- sum(preds_binary == 0 & labels == 1)
  balanced_acc <- 0.5 * (tp / (tp + fn + 1e-6) + tn / (tn + fp + 1e-6))
  # Return a list with the metric name and its value
  return(list(metric = "balanced_accuracy", value = balanced_acc))
}


final_params_xg <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eval_metric = "logloss", 
  eta = best_model_xg$eta,                 # Replace with the optimal eta value
  max_depth = best_model_xg$max_depth,     # Replace with the optimal max_depth
  subsample = best_model_xg$subsample,     # Replace with the optimal subsample value
  colsample_bytree = best_model_xg$colsample_bytree, # Replace with optimal colsample_bytree
  min_child_weight = best_model_xg$min_child_weight,
  gamma = best_model_xg$gamma,
  alpha = best_model_xg$alpha
  )



# XG MODEL using TRAIN data -----------
final_model_xg <- xgb.train(
  params = final_params_xg, 
  data = dtrain_xg, 
  nrounds = 100,                        # You can adjust the number of rounds based on early stopping results
  watchlist = list(train = dtrain_xg), 
  early_stopping_rounds = 10,           # Stop training if no improvement is seen in 10 rounds
  # feval = balanced_accuracy,
  # maximize = TRUE,
  verbose = 0                           # Optional: set to 0 for silent training
)

# Make predictions on the test data
predictions_xg_train <- predict(final_model_xg, dtrain_xg) 
# Default THRESHOLD
predictions_binary_xg_train <- ifelse(predictions_xg_train > 0.5, 1, 0)

# Evaluate the final model
accuracy_xg_train <- sum(predictions_binary_xg_train == y_train) / length(y_train)
print(paste("Final Accuracy for Train data with 0.5:", accuracy_xg_train))


conf_matrix_xg_train <- table(Predicted = predictions_binary_xg_train, Actual = y_train) # Confusion matrix train
print("Confusion Matrix:")
print(conf_matrix_xg_train)


importance_matrix_xg_train <- xgb.importance(model = final_model_xg)

# Calculate cumulative gain for the features
importance_matrix_xg_train$cumulative_gain <- cumsum(importance_matrix_xg_train$Gain)

# Print the importance matrix with cumulative gain
print(importance_matrix_xg_train)

# Select the top 25 features
top_features_xg <- importance_matrix_xg_train[1:10, ]

# Plot the top 25 features
xgb.plot.importance(
  importance_matrix = top_features_xg, 
  main = "Top 25 Most Important Features",
  xlab = "Feature Importance"
)
```



```{r}
library(ggplot2)
set.seed(12)
# Initialize an empty data frame to store results
predictions_xg_valid <- predict(final_model_xg, dvalid_xg) 
threshold_results_xg_valid <- data.frame(Threshold_xg = numeric(), BalancedAccuracy_xg = numeric())

# Define a sequence of threshold values
threshold_values_xg_valid <- seq(0, 1, by = 0.001)

# Loop through each threshold value
for (threshold_xg in threshold_values_xg_valid) {
  # Convert probabilities to binary predictions based on the current threshold
  predicted_classes_xg_valid <- ifelse(predictions_xg_valid > threshold_xg, 1, 0)
  
  # Calculate the confusion matrix
  conf_matrix_xg_valid <- table(Predicted_xg = predicted_classes_xg_valid, Actual_xg = y_valid)
  
  # Extract TP, TN, FP, FN (use tryCatch for error handling in case of missing categories)
  tn_xg <- tryCatch(conf_matrix_xg_valid[1, 1], error = function(e) 0)
  tp_xg <- tryCatch(conf_matrix_xg_valid[2, 2], error = function(e) 0)
  fp_xg <- tryCatch(conf_matrix_xg_valid[2, 1], error = function(e) 0)
  fn_xg <- tryCatch(conf_matrix_xg_valid[1, 2], error = function(e) 0)
  
  # Calculate balanced accuracy
  balan_acc_xg_valid <- 0.5 * (tp_xg / (tp_xg + fn_xg + 1e-6) + tn_xg / (tn_xg + fp_xg + 1e-6)) # Add small value to avoid division by zero
  
  # Append the results to the data frame
  threshold_results_xg_valid <- rbind(threshold_results_xg_valid, data.frame(Threshold_xg = threshold_xg, BalancedAccuracy_xg = balan_acc_xg_valid))
}

# Print the results
# print(threshold_results_xg)
png("example_chart34634.png", width = 1200, height = 800)

ggplot(threshold_results_xg_valid, aes(x = Threshold_xg, y = BalancedAccuracy_xg)) +
  geom_line(color = "black", size = 1) +
  labs(
    title = "Balanced Accuracy vs. Threshold (XGBoost)",
    x = "Threshold",
    y = "Balanced Accuracy"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    panel.grid.major = element_line(color = "grey90"),
    panel.grid.minor = element_blank(),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text = element_text(color = "black"),
    axis.title = element_text(face = "bold")
  )
dev.off() 
max_balanced_accuracy_xg <- threshold_results_xg_valid[which.max(threshold_results_xg_valid$BalancedAccuracy_xg), ]

# Output the results


cat("Threshold_xg:", max_balanced_accuracy_xg$Threshold_xg, "\n")
cat("Balanced Accuracy_xg:", max_balanced_accuracy_xg$BalancedAccuracy_xg, "\n")

```



```{r}
set.seed(12)
# BEST THRESHOLD BY VALIDATING
# 
predictions_xg_test <- predict(final_model_xg, dtest_xg) 
predicted_classes_xg_test <- ifelse(predictions_xg_test > max_balanced_accuracy_xg$Threshold_xg , 1, 0)
# TO TEST A PARTICULAR THRESHOLD:
# predicted_classes_xg_test <- ifelse(predictions_xg_test > 0.0395 , 1, 0)

conf_matrix_xg_test <- table(Predicted = predicted_classes_xg_test, Actual = y_test)
print("Confusion Matrix Test XG:")
print(conf_matrix_xg_test)

tn_xg_t = conf_matrix_xg_test[1,1]
tp_xg_t = conf_matrix_xg_test[2,2]
fp_xg_t = conf_matrix_xg_test[2,1]
fn_xg_t = conf_matrix_xg_test[1,2]

balan_acc_xg_test = 0.5*( tp_xg_t / (tp_xg_t+fn_xg_t) + tn_xg_t / (tn_xg_t + fp_xg_t) )
print(balan_acc_xg_test)

```

--------------------------------------------------
 NOW IM GOING TO WORK WITH LESS FEATURES
--------------------------------------------------

```{r}
library(xgboost)
library(data.table)

# Define the parameter grid
param_grid_xg <- expand.grid(
  max_depth = c(6,8),                   # Tree depth
  eta = c(0.15,0.2),                       # Learning rate
  subsample = c(0.8),                 # Fraction of rows sampled per boosting round
  colsample_bytree = c(0.8),     # Fraction of features sampled per tree
  min_child_weight = c(1, 2),         # Minimum sum of instance weight needed in a child
  gamma = c(0.1, 0.3,0.5),                # Minimum loss reduction for further partitioning
  alpha = c(3, 3.5, 4)                     # L1 regularization term
)

# Track the best model and results
best_model_xg <- NULL
best_logloss_xg <- Inf
best_params_xg_detailed <- NULL

# Create a data frame to store results
cv_results <- data.frame(
  max_depth = integer(),
  eta = numeric(),
  subsample = numeric(),
  colsample_bytree = numeric(),
  min_child_weight = numeric(),
  gamma = numeric(),
  alpha = numeric(),
  logloss = numeric(),
  num_features = integer(),           # Add a column to store the number of selected features
  stringsAsFactors = FALSE
)

# Cross-validation loop
set.seed(12)  # For reproducibility
for (i in 1:nrow(param_grid_xg)) {
  
  params_xg <- list(
    booster = "gbtree",
    objective = "binary:logistic",
    eval_metric = "logloss",
    max_depth = param_grid_xg$max_depth[i],
    eta = param_grid_xg$eta[i],
    subsample = param_grid_xg$subsample[i],
    colsample_bytree = param_grid_xg$colsample_bytree[i],
    min_child_weight = param_grid_xg$min_child_weight[i],
    gamma = param_grid_xg$gamma[i],
    alpha = param_grid_xg$alpha[i]
  )
  
  # Perform cross-validation
  cv <- xgb.cv(
    params = params_xg,
    data = dtrain_xg,
    nrounds = 100,
    nfold = 5,                        # 5-fold cross-validation
    early_stopping_rounds = 10,       # Stop if no improvement for 10 rounds
    verbose = FALSE
  )
  
  # Get the best logloss for this combination of parameters
  min_logloss <- min(cv$evaluation_log$test_logloss_mean)
  
  # Train a model to calculate feature importance
  model <- xgb.train(
    params = params_xg,
    data = dtrain_xg,
    nrounds = cv$best_iteration
  )
  
  # Get feature importance
  importance_matrix <- xgb.importance(model = model)
  num_features <- nrow(importance_matrix)  # Number of selected features based on importance
  
  # Store the results
  cv_results <- rbind(cv_results, data.frame(
    max_depth = param_grid_xg$max_depth[i],
    eta = param_grid_xg$eta[i],
    subsample = param_grid_xg$subsample[i],
    colsample_bytree = param_grid_xg$colsample_bytree[i],
    min_child_weight = param_grid_xg$min_child_weight[i],
    gamma = param_grid_xg$gamma[i],
    alpha = param_grid_xg$alpha[i],
    logloss = min_logloss,
    num_features = num_features           # Store the number of selected features
  ))
  
  # Update the best model if the logloss improves
  if (min_logloss < best_logloss_xg) {
    best_logloss_xg <- min_logloss
    best_model_xg <- params_xg
    best_params_xg_detailed <- params_xg
  }
  print(i)
}

# Print the complete cross-validation results
print(cv_results)

# Print the best parameters and the corresponding logloss
print("Best Hyperparameters for XGBoost:")
print(best_params_xg_detailed)
print(paste("Best Logloss:", best_logloss_xg))

```

```{r}
cv_results <- cv_results[order(cv_results$num_features, decreasing = TRUE), ]
print(cv_results)

# Filter rows where num_features is 136 and select the one with the lowest logloss
row_136 <- cv_results[cv_results$num_features == 136, ]
best_row_136 <- row_136[which.min(row_136$logloss), ]

# Filter rows where num_features is 118 and select the one with the lowest logloss
row_118 <- cv_results[cv_results$num_features == 118, ]
best_row_118 <- row_118[which.min(row_118$logloss), ]

# Create params_136 list
params_136 <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = best_row_136$max_depth,
  eta = best_row_136$eta,
  subsample = best_row_136$subsample,
  colsample_bytree = best_row_136$colsample_bytree,
  min_child_weight = best_row_136$min_child_weight,
  gamma = best_row_136$gamma,
  alpha = best_row_136$alpha
)

# Create params_118 list
params_118 <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = best_row_118$max_depth,
  eta = best_row_118$eta,
  subsample = best_row_118$subsample,
  colsample_bytree = best_row_118$colsample_bytree,
  min_child_weight = best_row_118$min_child_weight,
  gamma = best_row_118$gamma,
  alpha = best_row_118$alpha
)

# Print the parameter lists


final_model_xg_136 <- xgb.train(
  params = params_136, 
  data = dtrain_xg,
  watchlist = list(train = dtrain_xg),
  nrounds = 100,                        
  early_stopping_rounds = 10,          
  verbose = 0                           
)

final_model_xg_118 <- xgb.train(
  params = params_118, 
  data = dtrain_xg,
  watchlist = list(train = dtrain_xg),
  nrounds = 100,                        
  early_stopping_rounds = 10,          
  verbose = 0                           
)


```

```{r}

set.seed(12)

predictions_xg_valid_118 <- predict(final_model_xg_118, dvalid_xg) 
threshold_results_xg_valid_118 <- data.frame(Threshold_xg = numeric(), BalancedAccuracy_xg = numeric())

# Define a sequence of threshold values
threshold_values_xg_valid <- seq(0, 1, by = 0.001)

# Loop through each threshold value
for (threshold_xg in threshold_values_xg_valid) {
  # Convert probabilities to binary predictions based on the current threshold
  predicted_classes_xg_valid <- ifelse(predictions_xg_valid_118 > threshold_xg, 1, 0)
  
  # Calculate the confusion matrix
  conf_matrix_xg_valid_118 <- table(Predicted_xg = predicted_classes_xg_valid, Actual_xg = y_valid)
  
  # Extract TP, TN, FP, FN (use tryCatch for error handling in case of missing categories)
  tn_xg_118 <- tryCatch(conf_matrix_xg_valid_118[1, 1], error = function(e) 0)
  tp_xg_118 <- tryCatch(conf_matrix_xg_valid_118[2, 2], error = function(e) 0)
  fp_xg_118 <- tryCatch(conf_matrix_xg_valid_118[2, 1], error = function(e) 0)
  fn_xg_118 <- tryCatch(conf_matrix_xg_valid_118[1, 2], error = function(e) 0)
  
  # Calculate balanced accuracy
  balan_acc_xg_valid_118 <- 0.5 * (tp_xg_118 / (tp_xg_118 + fn_xg_118 + 1e-6) + tn_xg_118 / (tn_xg_118 + fp_xg_118 + 1e-6)) # Add small 
  
  # Append the results to the data frame
  threshold_results_xg_valid_118 <- rbind(threshold_results_xg_valid_118, data.frame(Threshold_xg = threshold_xg, BalancedAccuracy_xg = balan_acc_xg_valid_118))
}


max_balanced_accuracy_xg_118 <- threshold_results_xg_valid_118[which.max(threshold_results_xg_valid_118$BalancedAccuracy_xg), ]

# Output the results
cat("Threshold with Maximum Balanced Accuracy (XGBoost):\n")
cat("Threshold_xg:", max_balanced_accuracy_xg_118$Threshold_xg, "\n")
cat("Balanced Accuracy_xg:", max_balanced_accuracy_xg_118$BalancedAccuracy_xg, "\n")

predictions_xg_test_118 <- predict(final_model_xg_118, dtest_xg) 
predicted_classes_xg_test_118 <- ifelse(predictions_xg_test_118 > max_balanced_accuracy_xg_118$Threshold_xg , 1, 0)
# TO TEST A PARTICULAR THRESHOLD:
# predicted_classes_xg_test <- ifelse(predictions_xg_test > 0.0395 , 1, 0)

conf_matrix_xg_test_118 <- table(Predicted = predicted_classes_xg_test_118, Actual = y_test)

tn_xg_t_118 <- tryCatch(conf_matrix_xg_test_118[1, 1], error = function(e) 0)
tp_xg_t_118 <- tryCatch(conf_matrix_xg_test_118[2, 2], error = function(e) 0)
fp_xg_t_118 <- tryCatch(conf_matrix_xg_test_118[2, 1], error = function(e) 0)
fn_xg_t_118 <- tryCatch(conf_matrix_xg_test_118[1, 2], error = function(e) 0)



balan_acc_xg_test_118 = 0.5*( tp_xg_t_118 / (tp_xg_t_118+fn_xg_t_118) + tn_xg_t_118 / (tn_xg_t_118 + fp_xg_t_118) )
print(balan_acc_xg_test_118)

```

```{r}

set.seed(12)

predictions_xg_valid_136 <- predict(final_model_xg_136, dvalid_xg) 
threshold_results_xg_valid_136 <- data.frame(Threshold_xg = numeric(), BalancedAccuracy_xg = numeric())

# Define a sequence of threshold values
threshold_values_xg_valid <- seq(0, 1, by = 0.001)

# Loop through each threshold value
for (threshold_xg in threshold_values_xg_valid) {
  # Convert probabilities to binary predictions based on the current threshold
  predicted_classes_xg_valid <- ifelse(predictions_xg_valid_136 > threshold_xg, 1, 0)
  
  # Calculate the confusion matrix
  conf_matrix_xg_valid_136 <- table(Predicted_xg = predicted_classes_xg_valid, Actual_xg = y_valid)
  
  # Extract TP, TN, FP, FN (use tryCatch for error handling in case of missing categories)
  tn_xg_136 <- tryCatch(conf_matrix_xg_valid_136[1, 1], error = function(e) 0)
  tp_xg_136 <- tryCatch(conf_matrix_xg_valid_136[2, 2], error = function(e) 0)
  fp_xg_136 <- tryCatch(conf_matrix_xg_valid_136[2, 1], error = function(e) 0)
  fn_xg_136 <- tryCatch(conf_matrix_xg_valid_136[1, 2], error = function(e) 0)
  
  # Calculate balanced accuracy
  balan_acc_xg_valid_136 <- 0.5 * (tp_xg_136 / (tp_xg_136 + fn_xg_136 + 1e-6) + tn_xg_136 / (tn_xg_136 + fp_xg_136 + 1e-6)) # Add small 
  
  # Append the results to the data frame
  threshold_results_xg_valid_136 <- rbind(threshold_results_xg_valid_136, data.frame(Threshold_xg = threshold_xg, BalancedAccuracy_xg = balan_acc_xg_valid_136))
}


max_balanced_accuracy_xg_136 <- threshold_results_xg_valid_136[which.max(threshold_results_xg_valid_136$BalancedAccuracy_xg), ]

# Output the results
cat("Threshold with Maximum Balanced Accuracy (XGBoost):\n")
cat("Threshold_xg:", max_balanced_accuracy_xg_136$Threshold_xg, "\n")
cat("Balanced Accuracy_xg:", max_balanced_accuracy_xg_136$BalancedAccuracy_xg, "\n")

predictions_xg_test_136 <- predict(final_model_xg_136, dtest_xg) 
predicted_classes_xg_test_136 <- ifelse(predictions_xg_test_136 > max_balanced_accuracy_xg_136$Threshold_xg , 1, 0)
# TO TEST A PARTICULAR THRESHOLD:
# predicted_classes_xg_test <- ifelse(predictions_xg_test > 0.0395 , 1, 0)

conf_matrix_xg_test_136 <- table(Predicted = predicted_classes_xg_test_136, Actual = y_test)

tn_xg_t_136 <- tryCatch(conf_matrix_xg_test_136[1, 1], error = function(e) 0)
tp_xg_t_136 <- tryCatch(conf_matrix_xg_test_136[2, 2], error = function(e) 0)
fp_xg_t_136 <- tryCatch(conf_matrix_xg_test_136[2, 1], error = function(e) 0)
fn_xg_t_136 <- tryCatch(conf_matrix_xg_test_136[1, 2], error = function(e) 0)



balan_acc_xg_test_136 = 0.5*( tp_xg_t_136 / (tp_xg_t_136+fn_xg_t_136) + tn_xg_t_136 / (tn_xg_t_136 + fp_xg_t_136) )
print(balan_acc_xg_test_136)

```
--- 155 ---
Threshold with Maximum Balanced Accuracy (XGBoost):
Threshold_xg: 0.032 
Balanced Accuracy_xg: 0.8258928 
[1] 0.8126685

--- 136 ---
Threshold with Maximum Balanced Accuracy (XGBoost):
Threshold_xg: 0.036 
Balanced Accuracy_xg: 0.8303571 
[1] 0.7580863

--- 118 ---
Threshold with Maximum Balanced Accuracy (XGBoost):
Threshold_xg: 0.023 
Balanced Accuracy_xg: 0.8124999 
[1] 0.7021563


